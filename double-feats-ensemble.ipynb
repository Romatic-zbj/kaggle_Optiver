{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ba388967",
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2023-12-20T03:49:38.353732Z",
     "iopub.status.busy": "2023-12-20T03:49:38.353385Z",
     "iopub.status.idle": "2023-12-20T03:49:41.309019Z",
     "shell.execute_reply": "2023-12-20T03:49:41.307790Z"
    },
    "papermill": {
     "duration": 2.967244,
     "end_time": "2023-12-20T03:49:41.311574",
     "exception": false,
     "start_time": "2023-12-20T03:49:38.344330",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import gc  \n",
    "import os  \n",
    "import time  \n",
    "import warnings \n",
    "from itertools import combinations  \n",
    "from warnings import simplefilter \n",
    "import joblib  \n",
    "import lightgbm as lgb  \n",
    "import numpy as np  \n",
    "import pandas as pd  \n",
    "from sklearn.metrics import mean_absolute_error \n",
    "from sklearn.model_selection import KFold, TimeSeriesSplit  \n",
    "import polars as pl\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "simplefilter(action=\"ignore\", category=pd.errors.PerformanceWarning)\n",
    "\n",
    "is_offline = False \n",
    "LGB = True\n",
    "NN = False\n",
    "is_train = True  \n",
    "is_infer = True \n",
    "max_lookback = np.nan \n",
    "split_day = 435 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "83fd4250",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-20T03:49:41.327689Z",
     "iopub.status.busy": "2023-12-20T03:49:41.326635Z",
     "iopub.status.idle": "2023-12-20T03:49:41.332417Z",
     "shell.execute_reply": "2023-12-20T03:49:41.331335Z"
    },
    "papermill": {
     "duration": 0.015929,
     "end_time": "2023-12-20T03:49:41.334589",
     "exception": false,
     "start_time": "2023-12-20T03:49:41.318660",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection._split import _BaseKFold, indexable, _num_samples\n",
    "from sklearn.utils.validation import _deprecate_positional_args"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "77ca3439",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-20T03:49:41.349550Z",
     "iopub.status.busy": "2023-12-20T03:49:41.349221Z",
     "iopub.status.idle": "2023-12-20T03:49:41.361070Z",
     "shell.execute_reply": "2023-12-20T03:49:41.360102Z"
    },
    "papermill": {
     "duration": 0.02174,
     "end_time": "2023-12-20T03:49:41.363111",
     "exception": false,
     "start_time": "2023-12-20T03:49:41.341371",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def reduce_mem_usage(df, verbose=0):\n",
    "    start_mem = df.memory_usage().sum() / 1024**2\n",
    "    for col in df.columns:\n",
    "        col_type = df[col].dtype\n",
    "        if col_type != object:\n",
    "            c_min = df[col].min()\n",
    "            c_max = df[col].max()\n",
    "            \n",
    "            if str(col_type)[:3] == \"int\":\n",
    "                if c_min > np.iinfo(np.int8).min and c_max < np.iinfo(np.int8).max:\n",
    "                    df[col] = df[col].astype(np.int8)\n",
    "                elif c_min > np.iinfo(np.int16).min and c_max < np.iinfo(np.int16).max:\n",
    "                    df[col] = df[col].astype(np.int16)\n",
    "                elif c_min > np.iinfo(np.int32).min and c_max < np.iinfo(np.int32).max:\n",
    "                    df[col] = df[col].astype(np.int32)\n",
    "                elif c_min > np.iinfo(np.int64).min and c_max < np.iinfo(np.int64).max:\n",
    "                    df[col] = df[col].astype(np.int64)\n",
    "            else:\n",
    "               \n",
    "                if c_min > np.finfo(np.float16).min and c_max < np.finfo(np.float16).max:\n",
    "                    df[col] = df[col].astype(np.float32)\n",
    "                elif c_min > np.finfo(np.float32).min and c_max < np.finfo(np.float32).max:\n",
    "                    df[col] = df[col].astype(np.float32)\n",
    "                else:\n",
    "                    df[col] = df[col].astype(np.float32)\n",
    "    if verbose:\n",
    "        logger.info(f\"Memory usage of dataframe is {start_mem:.2f} MB\")\n",
    "        end_mem = df.memory_usage().sum() / 1024**2\n",
    "        logger.info(f\"Memory usage after optimization is: {end_mem:.2f} MB\")\n",
    "        decrease = 100 * (start_mem - end_mem) / start_mem\n",
    "        logger.info(f\"Decreased by {decrease:.2f}%\")\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3cb9a9fb",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-20T03:49:41.378171Z",
     "iopub.status.busy": "2023-12-20T03:49:41.377641Z",
     "iopub.status.idle": "2023-12-20T03:49:58.378063Z",
     "shell.execute_reply": "2023-12-20T03:49:58.376880Z"
    },
    "papermill": {
     "duration": 17.011238,
     "end_time": "2023-12-20T03:49:58.381151",
     "exception": false,
     "start_time": "2023-12-20T03:49:41.369913",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"/kaggle/input/optiver-trading-at-the-close/train.csv\")\n",
    "df = df.dropna(subset=[\"target\"])\n",
    "df.reset_index(drop=True, inplace=True)\n",
    "df_shape = df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1bf70b20",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-20T03:49:58.397310Z",
     "iopub.status.busy": "2023-12-20T03:49:58.396929Z",
     "iopub.status.idle": "2023-12-20T03:49:59.709555Z",
     "shell.execute_reply": "2023-12-20T03:49:59.708577Z"
    },
    "papermill": {
     "duration": 1.323598,
     "end_time": "2023-12-20T03:49:59.712040",
     "exception": false,
     "start_time": "2023-12-20T03:49:58.388442",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from numba import njit, prange\n",
    "\n",
    "@njit(parallel=True)\n",
    "def compute_triplet_imbalance(df_values, comb_indices):\n",
    "    num_rows = df_values.shape[0]\n",
    "    num_combinations = len(comb_indices)\n",
    "    imbalance_features = np.empty((num_rows, num_combinations))\n",
    "    for i in prange(num_combinations):\n",
    "        a, b, c = comb_indices[i]\n",
    "        for j in range(num_rows):\n",
    "            max_val = max(df_values[j, a], df_values[j, b], df_values[j, c])\n",
    "            min_val = min(df_values[j, a], df_values[j, b], df_values[j, c])\n",
    "            mid_val = df_values[j, a] + df_values[j, b] + df_values[j, c] - min_val - max_val\n",
    "            \n",
    "            if mid_val == min_val:\n",
    "                imbalance_features[j, i] = np.nan\n",
    "            else:\n",
    "                imbalance_features[j, i] = (max_val - mid_val) / (mid_val - min_val)\n",
    "\n",
    "    return imbalance_features\n",
    "\n",
    "def calculate_triplet_imbalance_numba(price, df):\n",
    "    df_values = df[price].values\n",
    "    comb_indices = [(price.index(a), price.index(b), price.index(c)) for a, b, c in combinations(price, 3)]\n",
    "    features_array = compute_triplet_imbalance(df_values, comb_indices)\n",
    "    columns = [f\"{a}_{b}_{c}_imb2\" for a, b, c in combinations(price, 3)]\n",
    "    features = pd.DataFrame(features_array, columns=columns)\n",
    "    return features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f91867d3",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-20T03:49:59.727577Z",
     "iopub.status.busy": "2023-12-20T03:49:59.727227Z",
     "iopub.status.idle": "2023-12-20T03:49:59.731676Z",
     "shell.execute_reply": "2023-12-20T03:49:59.730443Z"
    },
    "papermill": {
     "duration": 0.014795,
     "end_time": "2023-12-20T03:49:59.733840",
     "exception": false,
     "start_time": "2023-12-20T03:49:59.719045",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#160feats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0585ccfa",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-20T03:49:59.749694Z",
     "iopub.status.busy": "2023-12-20T03:49:59.749302Z",
     "iopub.status.idle": "2023-12-20T03:49:59.773953Z",
     "shell.execute_reply": "2023-12-20T03:49:59.773208Z"
    },
    "papermill": {
     "duration": 0.035121,
     "end_time": "2023-12-20T03:49:59.776025",
     "exception": false,
     "start_time": "2023-12-20T03:49:59.740904",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def imbalance_features_160feats(df):\n",
    "    # Define lists of price and size-related column names\n",
    "    prices = [\"reference_price\", \"far_price\", \"near_price\", \"ask_price\", \"bid_price\", \"wap\"]\n",
    "    sizes = [\"matched_size\", \"bid_size\", \"ask_size\", \"imbalance_size\"]\n",
    "    \n",
    "    df[\"volume\"] = df.eval(\"ask_size + bid_size\")\n",
    "    df[\"mid_price\"] = df.eval(\"(ask_price + bid_price) / 2\")\n",
    "    df[\"liquidity_imbalance\"] = df.eval(\"(bid_size-ask_size)/(bid_size+ask_size)\")\n",
    "    df[\"matched_imbalance\"] = df.eval(\"(imbalance_size-matched_size)/(matched_size+imbalance_size)\")\n",
    "    df[\"size_imbalance\"] = df.eval(\"bid_size / ask_size\")\n",
    "\n",
    "    for c in combinations(prices, 2):\n",
    "        df[f\"{c[0]}_{c[1]}_imb\"] = df.eval(f\"({c[0]} - {c[1]})/({c[0]} + {c[1]})\")\n",
    "\n",
    "    for c in [['ask_price', 'bid_price', 'wap', 'reference_price'], sizes]:\n",
    "        triplet_feature = calculate_triplet_imbalance_numba(c, df)\n",
    "        df[triplet_feature.columns] = triplet_feature.values\n",
    "    \n",
    "    df[\"stock_weights\"] = df[\"stock_id\"].map(weights)\n",
    "    df[\"weighted_wap\"] = df[\"stock_weights\"] * df[\"wap\"]\n",
    "    df['wap_momentum'] = df.groupby('stock_id')['weighted_wap'].pct_change(periods=6)\n",
    "   \n",
    "    df[\"imbalance_momentum\"] = df.groupby(['stock_id'])['imbalance_size'].diff(periods=1) / df['matched_size']\n",
    "    df[\"price_spread\"] = df[\"ask_price\"] - df[\"bid_price\"]\n",
    "    df[\"spread_intensity\"] = df.groupby(['stock_id'])['price_spread'].diff()\n",
    "    df['price_pressure'] = df['imbalance_size'] * (df['ask_price'] - df['bid_price'])\n",
    "    df['market_urgency'] = df['price_spread'] * df['liquidity_imbalance']\n",
    "    df['depth_pressure'] = (df['ask_size'] - df['bid_size']) * (df['far_price'] - df['near_price'])\n",
    "    \n",
    "    df['spread_depth_ratio'] = (df['ask_price'] - df['bid_price']) / (df['bid_size'] + df['ask_size'])\n",
    "    df['mid_price_movement'] = df['mid_price'].diff(periods=5).apply(lambda x: 1 if x > 0 else (-1 if x < 0 else 0))\n",
    "    \n",
    "    df['micro_price'] = ((df['bid_price'] * df['ask_size']) + (df['ask_price'] * df['bid_size'])) / (df['bid_size'] + df['ask_size'])\n",
    "    df['relative_spread'] = (df['ask_price'] - df['bid_price']) / df['wap']\n",
    "    \n",
    "    # Calculate various statistical aggregation features\n",
    "    for func in [\"mean\", \"std\", \"skew\", \"kurt\"]:\n",
    "        df[f\"all_prices_{func}\"] = df[prices].agg(func, axis=1)\n",
    "        df[f\"all_sizes_{func}\"] = df[sizes].agg(func, axis=1)\n",
    "        \n",
    "\n",
    "    for col in ['matched_size', 'imbalance_size', 'reference_price', 'imbalance_buy_sell_flag']:\n",
    "        for window in [1,3,5,10]:\n",
    "            df[f\"{col}_shift_{window}\"] = df.groupby('stock_id')[col].shift(window)\n",
    "            df[f\"{col}_ret_{window}\"] = df.groupby('stock_id')[col].pct_change(window)\n",
    "    \n",
    "    # Calculate diff features for specific columns\n",
    "    for col in ['ask_price', 'bid_price', 'ask_size', 'bid_size', 'weighted_wap','price_spread']:\n",
    "        for window in [1,3,5,10]:\n",
    "            df[f\"{col}_diff_{window}\"] = df.groupby(\"stock_id\")[col].diff(window)\n",
    "    \n",
    "    #V4 feature\n",
    "    for window in [3,5,10]:\n",
    "        df[f'price_change_diff_{window}'] = df[f'bid_price_diff_{window}'] - df[f'ask_price_diff_{window}']\n",
    "        df[f'size_change_diff_{window}'] = df[f'bid_size_diff_{window}'] - df[f'ask_size_diff_{window}']\n",
    "\n",
    "    #V5 - rolling diff\n",
    "    # Convert from pandas to Polars\n",
    "    pl_df = pl.from_pandas(df)\n",
    "\n",
    "    #Define the windows and columns for which you want to calculate the rolling statistics\n",
    "    windows = [3, 5, 10]\n",
    "    columns = ['ask_price', 'bid_price', 'ask_size', 'bid_size']\n",
    "\n",
    "    # prepare the operations for each column and window\n",
    "    group = [\"stock_id\"]\n",
    "    expressions = []\n",
    "\n",
    "    # Loop over each window and column to create the rolling mean and std expressions\n",
    "    for window in windows:\n",
    "        for col in columns:\n",
    "            rolling_mean_expr = (\n",
    "                pl.col(f\"{col}_diff_{window}\")\n",
    "                .rolling_mean(window)\n",
    "                .over(group)\n",
    "                .alias(f'rolling_diff_{col}_{window}')\n",
    "            )\n",
    "\n",
    "            rolling_std_expr = (\n",
    "                pl.col(f\"{col}_diff_{window}\")\n",
    "                .rolling_std(window)\n",
    "                .over(group)\n",
    "                .alias(f'rolling_std_diff_{col}_{window}')\n",
    "            )\n",
    "\n",
    "            expressions.append(rolling_mean_expr)\n",
    "            expressions.append(rolling_std_expr)\n",
    "\n",
    "    # Run the operations using Polars' lazy API\n",
    "    lazy_df = pl_df.lazy().with_columns(expressions)\n",
    "\n",
    "    # Execute the lazy expressions and overwrite the pl_df variable\n",
    "    pl_df = lazy_df.collect()\n",
    "\n",
    "    # Convert back to pandas if necessary\n",
    "    df = pl_df.to_pandas()\n",
    "    gc.collect()\n",
    "    \n",
    "    df['mid_price*volume'] = df['mid_price_movement'] * df['volume']\n",
    "    df['harmonic_imbalance'] = df.eval('2 / ((1 / bid_size) + (1 / ask_size))')\n",
    "    \n",
    "    for col in df.columns:\n",
    "        df[col] = df[col].replace([np.inf, -np.inf], 0)\n",
    "\n",
    "    return df\n",
    "\n",
    "def other_features_160feats(df):\n",
    "    df[\"dow\"] = df[\"date_id\"] % 5  # Day of the week\n",
    "    df[\"seconds\"] = df[\"seconds_in_bucket\"] % 60  \n",
    "    df[\"minute\"] = df[\"seconds_in_bucket\"] // 60  \n",
    "    df['time_to_market_close'] = 540 - df['seconds_in_bucket']\n",
    "    \n",
    "    for key, value in global_stock_id_feats.items():\n",
    "        df[f\"global_{key}\"] = df[\"stock_id\"].map(value.to_dict())\n",
    "\n",
    "    return df\n",
    "\n",
    "def generate_all_features_160feats(df):\n",
    "    # Select relevant columns for feature generation\n",
    "    cols = [c for c in df.columns if c not in [\"row_id\", \"time_id\", \"target\"]]\n",
    "    df = df[cols]\n",
    "    \n",
    "    # Generate imbalance features\n",
    "    df = imbalance_features_160feats(df)\n",
    "    gc.collect() \n",
    "    df = other_features_160feats(df)\n",
    "    gc.collect()  \n",
    "    feature_name = [i for i in df.columns if i not in [\"row_id\", \"target\", \"time_id\", \"date_id\"]]\n",
    "    \n",
    "    return df[feature_name]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "09c83997",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-20T03:49:59.791349Z",
     "iopub.status.busy": "2023-12-20T03:49:59.790939Z",
     "iopub.status.idle": "2023-12-20T03:49:59.797020Z",
     "shell.execute_reply": "2023-12-20T03:49:59.796002Z"
    },
    "papermill": {
     "duration": 0.016116,
     "end_time": "2023-12-20T03:49:59.799052",
     "exception": false,
     "start_time": "2023-12-20T03:49:59.782936",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Online mode\n"
     ]
    }
   ],
   "source": [
    "if is_offline:\n",
    "    \n",
    "    df_train = df[df[\"date_id\"] <= split_day]\n",
    "    df_valid = df[df[\"date_id\"] > split_day]\n",
    "    print(\"Offline mode\")\n",
    "    print(f\"train : {df_train.shape}, valid : {df_valid.shape}\")\n",
    "    \n",
    "else:\n",
    "    df_train = df\n",
    "    print(\"Online mode\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "aa28ebcc",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-20T03:49:59.813908Z",
     "iopub.status.busy": "2023-12-20T03:49:59.813577Z",
     "iopub.status.idle": "2023-12-20T03:50:01.513796Z",
     "shell.execute_reply": "2023-12-20T03:50:01.512388Z"
    },
    "papermill": {
     "duration": 1.710628,
     "end_time": "2023-12-20T03:50:01.516360",
     "exception": false,
     "start_time": "2023-12-20T03:49:59.805732",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "global_stock_id_feats = {\n",
    "        \"median_size\": df_train.groupby(\"stock_id\")[\"bid_size\"].median() + df_train.groupby(\"stock_id\")[\"ask_size\"].median(),\n",
    "        \"std_size\": df_train.groupby(\"stock_id\")[\"bid_size\"].std() + df_train.groupby(\"stock_id\")[\"ask_size\"].std(),\n",
    "        \"ptp_size\": df_train.groupby(\"stock_id\")[\"bid_size\"].max() - df_train.groupby(\"stock_id\")[\"bid_size\"].min(),\n",
    "        \"median_price\": df_train.groupby(\"stock_id\")[\"bid_price\"].median() + df_train.groupby(\"stock_id\")[\"ask_price\"].median(),\n",
    "        \"std_price\": df_train.groupby(\"stock_id\")[\"bid_price\"].std() + df_train.groupby(\"stock_id\")[\"ask_price\"].std(),\n",
    "        \"ptp_price\": df_train.groupby(\"stock_id\")[\"bid_price\"].max() - df_train.groupby(\"stock_id\")[\"ask_price\"].min(),\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "936de5cd",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-20T03:50:01.533491Z",
     "iopub.status.busy": "2023-12-20T03:50:01.533060Z",
     "iopub.status.idle": "2023-12-20T03:50:01.537221Z",
     "shell.execute_reply": "2023-12-20T03:50:01.536213Z"
    },
    "papermill": {
     "duration": 0.014579,
     "end_time": "2023-12-20T03:50:01.539380",
     "exception": false,
     "start_time": "2023-12-20T03:50:01.524801",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#124feats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "4aca843a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-20T03:50:01.554748Z",
     "iopub.status.busy": "2023-12-20T03:50:01.554447Z",
     "iopub.status.idle": "2023-12-20T03:50:01.568932Z",
     "shell.execute_reply": "2023-12-20T03:50:01.568086Z"
    },
    "papermill": {
     "duration": 0.02494,
     "end_time": "2023-12-20T03:50:01.571095",
     "exception": false,
     "start_time": "2023-12-20T03:50:01.546155",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def imbalance_features_124feats(df):\n",
    "    # Define lists of price and size-related column names\n",
    "    prices = [\"reference_price\", \"far_price\", \"near_price\", \"ask_price\", \"bid_price\", \"wap\"]\n",
    "    sizes = [\"matched_size\", \"bid_size\", \"ask_size\", \"imbalance_size\"]\n",
    "    df[\"volume\"] = df.eval(\"ask_size + bid_size\")\n",
    "    df[\"mid_price\"] = df.eval(\"(ask_price + bid_price) / 2\")\n",
    "    df[\"liquidity_imbalance\"] = df.eval(\"(bid_size-ask_size)/(bid_size+ask_size)\")\n",
    "    df[\"matched_imbalance\"] = df.eval(\"(imbalance_size-matched_size)/(matched_size+imbalance_size)\")\n",
    "    df[\"size_imbalance\"] = df.eval(\"bid_size / ask_size\")\n",
    "\n",
    "    for c in combinations(prices, 2):\n",
    "        df[f\"{c[0]}_{c[1]}_imb\"] = df.eval(f\"({c[0]} - {c[1]})/({c[0]} + {c[1]})\")\n",
    "\n",
    "    for c in [['ask_price', 'bid_price', 'wap', 'reference_price'], sizes]:\n",
    "        triplet_feature = calculate_triplet_imbalance_numba(c, df)\n",
    "        df[triplet_feature.columns] = triplet_feature.values\n",
    "   \n",
    "    df[\"imbalance_momentum\"] = df.groupby(['stock_id'])['imbalance_size'].diff(periods=1) / df['matched_size']\n",
    "    df[\"price_spread\"] = df[\"ask_price\"] - df[\"bid_price\"]\n",
    "    df[\"spread_intensity\"] = df.groupby(['stock_id'])['price_spread'].diff()\n",
    "    df['price_pressure'] = df['imbalance_size'] * (df['ask_price'] - df['bid_price'])\n",
    "    df['market_urgency'] = df['price_spread'] * df['liquidity_imbalance']\n",
    "    df['depth_pressure'] = (df['ask_size'] - df['bid_size']) * (df['far_price'] - df['near_price'])\n",
    "    \n",
    "    # Calculate various statistical aggregation features\n",
    "    for func in [\"mean\", \"std\", \"skew\", \"kurt\"]:\n",
    "        df[f\"all_prices_{func}\"] = df[prices].agg(func, axis=1)\n",
    "        df[f\"all_sizes_{func}\"] = df[sizes].agg(func, axis=1)\n",
    "        \n",
    "\n",
    "    for col in ['matched_size', 'imbalance_size', 'reference_price', 'imbalance_buy_sell_flag']:\n",
    "        for window in [1, 2, 3, 10]:\n",
    "            df[f\"{col}_shift_{window}\"] = df.groupby('stock_id')[col].shift(window)\n",
    "            df[f\"{col}_ret_{window}\"] = df.groupby('stock_id')[col].pct_change(window)\n",
    "    \n",
    "    # Calculate diff features for specific columns\n",
    "    for col in ['ask_price', 'bid_price', 'ask_size', 'bid_size', 'market_urgency', 'imbalance_momentum', 'size_imbalance']:\n",
    "        for window in [1, 2, 3, 10]:\n",
    "            df[f\"{col}_diff_{window}\"] = df.groupby(\"stock_id\")[col].diff(window)\n",
    "\n",
    "    return df.replace([np.inf, -np.inf], 0)\n",
    "\n",
    "def other_features_124feats(df):\n",
    "    df[\"dow\"] = df[\"date_id\"] % 5  # Day of the week\n",
    "    df[\"seconds\"] = df[\"seconds_in_bucket\"] % 60  \n",
    "    df[\"minute\"] = df[\"seconds_in_bucket\"] // 60  \n",
    "    for key, value in global_stock_id_feats.items():\n",
    "        df[f\"global_{key}\"] = df[\"stock_id\"].map(value.to_dict())\n",
    "\n",
    "    return df\n",
    "\n",
    "def generate_all_features_124feats(df):\n",
    "    # Select relevant columns for feature generation\n",
    "    cols = [c for c in df.columns if c not in [\"row_id\", \"time_id\", \"target\"]]\n",
    "    df = df[cols]\n",
    "    \n",
    "    # Generate imbalance features\n",
    "    df = imbalance_features_124feats(df)\n",
    "    df = other_features_124feats(df)\n",
    "    gc.collect()  \n",
    "    feature_name = [i for i in df.columns if i not in [\"row_id\", \"target\", \"time_id\", \"date_id\"]]\n",
    "    \n",
    "    return df[feature_name]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e6a94f1a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-20T03:50:01.586865Z",
     "iopub.status.busy": "2023-12-20T03:50:01.585876Z",
     "iopub.status.idle": "2023-12-20T03:50:01.590476Z",
     "shell.execute_reply": "2023-12-20T03:50:01.589622Z"
    },
    "papermill": {
     "duration": 0.014589,
     "end_time": "2023-12-20T03:50:01.592627",
     "exception": false,
     "start_time": "2023-12-20T03:50:01.578038",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#不知道什么意思的weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f114285a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-20T03:50:01.608793Z",
     "iopub.status.busy": "2023-12-20T03:50:01.608095Z",
     "iopub.status.idle": "2023-12-20T03:50:01.619036Z",
     "shell.execute_reply": "2023-12-20T03:50:01.618300Z"
    },
    "papermill": {
     "duration": 0.021251,
     "end_time": "2023-12-20T03:50:01.620814",
     "exception": false,
     "start_time": "2023-12-20T03:50:01.599563",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "weights = [\n",
    "    0.004, 0.001, 0.002, 0.006, 0.004, 0.004, 0.002, 0.006, 0.006, 0.002, 0.002, 0.008,\n",
    "    0.006, 0.002, 0.008, 0.006, 0.002, 0.006, 0.004, 0.002, 0.004, 0.001, 0.006, 0.004,\n",
    "    0.002, 0.002, 0.004, 0.002, 0.004, 0.004, 0.001, 0.001, 0.002, 0.002, 0.006, 0.004,\n",
    "    0.004, 0.004, 0.006, 0.002, 0.002, 0.04 , 0.002, 0.002, 0.004, 0.04 , 0.002, 0.001,\n",
    "    0.006, 0.004, 0.004, 0.006, 0.001, 0.004, 0.004, 0.002, 0.006, 0.004, 0.006, 0.004,\n",
    "    0.006, 0.004, 0.002, 0.001, 0.002, 0.004, 0.002, 0.008, 0.004, 0.004, 0.002, 0.004,\n",
    "    0.006, 0.002, 0.004, 0.004, 0.002, 0.004, 0.004, 0.004, 0.001, 0.002, 0.002, 0.008,\n",
    "    0.02 , 0.004, 0.006, 0.002, 0.02 , 0.002, 0.002, 0.006, 0.004, 0.002, 0.001, 0.02,\n",
    "    0.006, 0.001, 0.002, 0.004, 0.001, 0.002, 0.006, 0.006, 0.004, 0.006, 0.001, 0.002,\n",
    "    0.004, 0.006, 0.006, 0.001, 0.04 , 0.006, 0.002, 0.004, 0.002, 0.002, 0.006, 0.002,\n",
    "    0.002, 0.004, 0.006, 0.006, 0.002, 0.002, 0.008, 0.006, 0.004, 0.002, 0.006, 0.002,\n",
    "    0.004, 0.006, 0.002, 0.004, 0.001, 0.004, 0.002, 0.004, 0.008, 0.006, 0.008, 0.002,\n",
    "    0.004, 0.002, 0.001, 0.004, 0.004, 0.004, 0.006, 0.008, 0.004, 0.001, 0.001, 0.002,\n",
    "    0.006, 0.004, 0.001, 0.002, 0.006, 0.004, 0.006, 0.008, 0.002, 0.002, 0.004, 0.002,\n",
    "    0.04 , 0.002, 0.002, 0.004, 0.002, 0.002, 0.006, 0.02 , 0.004, 0.002, 0.006, 0.02,\n",
    "    0.001, 0.002, 0.006, 0.004, 0.006, 0.004, 0.004, 0.004, 0.004, 0.002, 0.004, 0.04,\n",
    "    0.002, 0.008, 0.002, 0.004, 0.001, 0.004, 0.006, 0.004,\n",
    "]\n",
    "weights = {int(k):v for k,v in enumerate(weights)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "8f9bbac5",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-20T03:50:01.636571Z",
     "iopub.status.busy": "2023-12-20T03:50:01.635602Z",
     "iopub.status.idle": "2023-12-20T03:50:01.641178Z",
     "shell.execute_reply": "2023-12-20T03:50:01.639966Z"
    },
    "papermill": {
     "duration": 0.015412,
     "end_time": "2023-12-20T03:50:01.643129",
     "exception": false,
     "start_time": "2023-12-20T03:50:01.627717",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def zero_sum(prices, volumes):\n",
    "    std_error = np.sqrt(volumes)\n",
    "    step = np.sum(prices) / np.sum(std_error)\n",
    "    out = prices - std_error * step\n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "7a4144de",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-20T03:50:01.658602Z",
     "iopub.status.busy": "2023-12-20T03:50:01.657594Z",
     "iopub.status.idle": "2023-12-20T03:50:01.662481Z",
     "shell.execute_reply": "2023-12-20T03:50:01.661383Z"
    },
    "papermill": {
     "duration": 0.014589,
     "end_time": "2023-12-20T03:50:01.664482",
     "exception": false,
     "start_time": "2023-12-20T03:50:01.649893",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "models_124feats=[]\n",
    "models_160feats=[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "278d2ad0",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-20T03:50:01.679837Z",
     "iopub.status.busy": "2023-12-20T03:50:01.678942Z",
     "iopub.status.idle": "2023-12-20T03:50:01.684062Z",
     "shell.execute_reply": "2023-12-20T03:50:01.682993Z"
    },
    "papermill": {
     "duration": 0.014989,
     "end_time": "2023-12-20T03:50:01.686228",
     "exception": false,
     "start_time": "2023-12-20T03:50:01.671239",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#lightGBM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "14f0067a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-20T03:50:01.702408Z",
     "iopub.status.busy": "2023-12-20T03:50:01.701777Z",
     "iopub.status.idle": "2023-12-20T03:50:15.183771Z",
     "shell.execute_reply": "2023-12-20T03:50:15.182905Z"
    },
    "papermill": {
     "duration": 13.492629,
     "end_time": "2023-12-20T03:50:15.186237",
     "exception": false,
     "start_time": "2023-12-20T03:50:01.693608",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "for fold in range(0,5):\n",
    "    filename = f\"/kaggle/input/lightgbm-5-fold-cv-param/lb5.3375/modelitos_para_despues/doblez_{fold+1}.txt\"\n",
    "    m = lgb.Booster(model_file=filename)\n",
    "    models_124feats.append(m)\n",
    "models_124feats.append(lgb.Booster(model_file=f\"/kaggle/input/lightgbm-5-fold-cv-param/lb5.3375/modelitos_para_despues/doblez-conjunto.txt\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "904957eb",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-20T03:50:15.201613Z",
     "iopub.status.busy": "2023-12-20T03:50:15.201266Z",
     "iopub.status.idle": "2023-12-20T03:50:30.286618Z",
     "shell.execute_reply": "2023-12-20T03:50:30.285709Z"
    },
    "papermill": {
     "duration": 15.095622,
     "end_time": "2023-12-20T03:50:30.288984",
     "exception": false,
     "start_time": "2023-12-20T03:50:15.193362",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "for fold in range(0,5):\n",
    "    filename = f\"/kaggle/input/lightgbm-160feats/lb5.3359/modelitos_para_despues/doblez_{fold+1}.txt\"\n",
    "    m = lgb.Booster(model_file=filename)\n",
    "    models_160feats.append(m)\n",
    "models_160feats.append(lgb.Booster(model_file=f\"/kaggle/input/lightgbm-160feats/lb5.3359/modelitos_para_despues/doblez-conjunto.txt\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "f15a4577",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-20T03:50:30.304824Z",
     "iopub.status.busy": "2023-12-20T03:50:30.304462Z",
     "iopub.status.idle": "2023-12-20T03:50:30.477613Z",
     "shell.execute_reply": "2023-12-20T03:50:30.476760Z"
    },
    "papermill": {
     "duration": 0.183734,
     "end_time": "2023-12-20T03:50:30.480021",
     "exception": false,
     "start_time": "2023-12-20T03:50:30.296287",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import xgboost\n",
    "from xgboost import XGBRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "f715f61d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-20T03:50:30.495311Z",
     "iopub.status.busy": "2023-12-20T03:50:30.494956Z",
     "iopub.status.idle": "2023-12-20T03:50:41.906608Z",
     "shell.execute_reply": "2023-12-20T03:50:41.905706Z"
    },
    "papermill": {
     "duration": 11.422133,
     "end_time": "2023-12-20T03:50:41.909191",
     "exception": false,
     "start_time": "2023-12-20T03:50:30.487058",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "for fold in range(0,5):\n",
    "    filename = f\"/kaggle/input/xgboost-5-fold-param/lb5.3377(1)modelitos_para_xgb/modelitos_para_xgb/doblez_{fold+1}.txt\"\n",
    "    models_124feats.append(joblib.load(filename))\n",
    "models_124feats.append(joblib.load(f\"/kaggle/input/xgboost-5-fold-param/lb5.3377(1)modelitos_para_xgb/modelitos_para_xgb/doblez-conjunto.txt\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "f16a33fe",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-20T03:50:41.924841Z",
     "iopub.status.busy": "2023-12-20T03:50:41.924112Z",
     "iopub.status.idle": "2023-12-20T03:50:56.877066Z",
     "shell.execute_reply": "2023-12-20T03:50:56.876043Z"
    },
    "papermill": {
     "duration": 14.963213,
     "end_time": "2023-12-20T03:50:56.879514",
     "exception": false,
     "start_time": "2023-12-20T03:50:41.916301",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "for fold in range(0,5):\n",
    "    filename = f\"/kaggle/input/xgboost-testdata-160feats/n6000(1)modelitos_para_xgb160feats/n6000(1)modelitos_para_xgb160feats/doblez_{fold+1}.txt\"\n",
    "    models_160feats.append(joblib.load(filename))\n",
    "models_160feats.append(joblib.load(f\"/kaggle/input/xgboost-testdata-160feats/n6000(1)modelitos_para_xgb160feats/n6000(1)modelitos_para_xgb160feats/doblez-conjunto.txt\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "9935c6b6",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-20T03:50:56.895679Z",
     "iopub.status.busy": "2023-12-20T03:50:56.895321Z",
     "iopub.status.idle": "2023-12-20T03:50:57.165655Z",
     "shell.execute_reply": "2023-12-20T03:50:57.164691Z"
    },
    "papermill": {
     "duration": 0.280801,
     "end_time": "2023-12-20T03:50:57.168001",
     "exception": false,
     "start_time": "2023-12-20T03:50:56.887200",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import catboost\n",
    "from catboost import CatBoostRegressor\n",
    "from catboost import EShapCalcType, EFeaturesSelectionAlgorithm\n",
    "from catboost import Pool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "da79c87e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-20T03:50:57.183282Z",
     "iopub.status.busy": "2023-12-20T03:50:57.182927Z",
     "iopub.status.idle": "2023-12-20T03:51:02.669760Z",
     "shell.execute_reply": "2023-12-20T03:51:02.668832Z"
    },
    "papermill": {
     "duration": 5.4969,
     "end_time": "2023-12-20T03:51:02.672077",
     "exception": false,
     "start_time": "2023-12-20T03:50:57.175177",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "for fold in range(0,5):\n",
    "    filename = f\"/kaggle/input/5-fold-cv-catboost/modelitos_para_cat/modelitos_para_cat/doblez_{fold+1}.txt\"\n",
    "    cat_model = CatBoostRegressor()  \n",
    "    cat_model.load_model(filename)\n",
    "    models_124feats.append(cat_model)\n",
    "cat_model = CatBoostRegressor()  \n",
    "models_124feats.append(cat_model.load_model(f\"/kaggle/input/5-fold-cv-catboost/modelitos_para_cat/modelitos_para_cat/doblez-conjunto.txt\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "23b7e158",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-20T03:51:02.687964Z",
     "iopub.status.busy": "2023-12-20T03:51:02.687605Z",
     "iopub.status.idle": "2023-12-20T03:51:08.835082Z",
     "shell.execute_reply": "2023-12-20T03:51:08.833610Z"
    },
    "papermill": {
     "duration": 6.157838,
     "end_time": "2023-12-20T03:51:08.836999",
     "exception": false,
     "start_time": "2023-12-20T03:51:02.679161",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "for fold in range(0,5):\n",
    "    filename = f\"/kaggle/input/catboost-test-dataset-160feats/n4000modelitos_para_cat_160_feats/n4000modelitos_para_cat_160_feats/doblez_{fold+1}.txt\"\n",
    "    cat_model = CatBoostRegressor()  \n",
    "    cat_model.load_model(filename)\n",
    "    models_160feats.append(cat_model)\n",
    "cat_model = CatBoostRegressor()  \n",
    "models_160feats.append(cat_model.load_model(f\"/kaggle/input/catboost-test-dataset-160feats/n4000modelitos_para_cat_160_feats/n4000modelitos_para_cat_160_feats/doblez-conjunto.txt\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "c6082473",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-20T03:51:08.851830Z",
     "iopub.status.busy": "2023-12-20T03:51:08.851509Z",
     "iopub.status.idle": "2023-12-20T03:51:08.858233Z",
     "shell.execute_reply": "2023-12-20T03:51:08.857477Z"
    },
    "papermill": {
     "duration": 0.016213,
     "end_time": "2023-12-20T03:51:08.860139",
     "exception": false,
     "start_time": "2023-12-20T03:51:08.843926",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18\n",
      "18\n"
     ]
    }
   ],
   "source": [
    "print(len(models_124feats))\n",
    "print(len(models_160feats))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "3ef4220f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-20T03:51:08.874679Z",
     "iopub.status.busy": "2023-12-20T03:51:08.874381Z",
     "iopub.status.idle": "2023-12-20T03:51:08.893745Z",
     "shell.execute_reply": "2023-12-20T03:51:08.892992Z"
    },
    "papermill": {
     "duration": 0.028893,
     "end_time": "2023-12-20T03:51:08.895785",
     "exception": false,
     "start_time": "2023-12-20T03:51:08.866892",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import optiver2023\n",
    "env = optiver2023.make_env()\n",
    "iter_test = env.iter_test()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "00a29e34",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-20T03:51:08.911873Z",
     "iopub.status.busy": "2023-12-20T03:51:08.911303Z",
     "iopub.status.idle": "2023-12-20T04:02:04.709158Z",
     "shell.execute_reply": "2023-12-20T04:02:04.707938Z"
    },
    "papermill": {
     "duration": 655.808628,
     "end_time": "2023-12-20T04:02:04.711551",
     "exception": false,
     "start_time": "2023-12-20T03:51:08.902923",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9999999999999999\n",
      "This version of the API is not optimized and should not be used to estimate the runtime of your code on the hidden test set.\n",
      "10 qps: 4.050453996658325\n",
      "20 qps: 4.002366232872009\n",
      "30 qps: 3.9961617867151897\n",
      "40 qps: 3.995497077703476\n",
      "50 qps: 3.990885329246521\n",
      "60 qps: 3.995203506946564\n",
      "70 qps: 3.996341449873788\n",
      "80 qps: 3.996765974164009\n",
      "90 qps: 3.9952943139606054\n",
      "100 qps: 3.9894211196899416\n",
      "110 qps: 3.981524216045033\n",
      "120 qps: 3.980930197238922\n",
      "130 qps: 3.977376415179326\n",
      "140 qps: 3.9759856138910568\n",
      "150 qps: 3.9725214131673177\n",
      "160 qps: 3.970848318934441\n",
      "The code will take approximately 4.5493 hours to reason about\n"
     ]
    }
   ],
   "source": [
    "counter = 0\n",
    "y_min, y_max = -64, 64\n",
    "qps, predictions = [], []\n",
    "cache = pd.DataFrame()\n",
    "\n",
    "\n",
    "# Weights for each fold model\n",
    "# model_weights = [1/len(models)] * len(models) \n",
    "# model_weights = [1/60,1/60,1/60,1/60,3/60,3/60]*6 #LB0.3377\n",
    "model_weights = [1/30,1/30,1/30,1/30,3/30,3/30]*3 #LB0.3377\n",
    "# model_weights = [3/40,3/40,3/40,3/40,9/40,9/40] + [1/50,1/50,1/50,1/50,3/50,3/50] + [1/200,1/200,1/200,1/200,3/200,3/200]#LB0.3377\n",
    "print(sum(model_weights))\n",
    "    \n",
    "for (test, revealed_targets, sample_prediction) in iter_test:\n",
    "    now_time = time.time()\n",
    "    \n",
    "    columns_given = ['seconds_in_bucket', 'imbalance_size','imbalance_buy_sell_flag', 'reference_price', 'matched_size','far_price', \n",
    "                     'near_price', 'bid_price', 'bid_size','ask_price', 'ask_size', 'wap',]\n",
    "    test[columns_given] = test[columns_given].astype(float)\n",
    "    \n",
    "    \n",
    "    cache = pd.concat([cache, test], ignore_index=True, axis=0)\n",
    "    if counter > 0:\n",
    "        cache = cache.groupby(['stock_id']).tail(21).sort_values(by=['date_id', 'seconds_in_bucket', 'stock_id']).reset_index(drop=True)\n",
    "    \n",
    "    \n",
    "    feats124 = generate_all_features_124feats(cache)[-len(test):]\n",
    "    # Generate predictions for each model and calculate the weighted average\n",
    "    feats124_predictions = np.zeros(len(test))\n",
    "    for model, weight in zip(models_124feats, model_weights):\n",
    "        feats124_predictions += weight * model.predict(feats124.drop('currently_scored', axis=1))\n",
    "\n",
    "    feats124_predictions = zero_sum(feats124_predictions, test['bid_size'] + test['ask_size'])\n",
    "    clipped_predictions = np.clip(feats124_predictions, y_min, y_max)\n",
    "    sample_prediction['target'] = clipped_predictions\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    feats160 = generate_all_features_160feats(cache)[-len(test):]\n",
    "    # Generate predictions for each model and calculate the weighted average\n",
    "    feats160_predictions = np.zeros(len(test))\n",
    "    for model, weight in zip(models_160feats, model_weights):\n",
    "        feats160_predictions += weight * model.predict(feats160.drop('currently_scored', axis=1))\n",
    "\n",
    "    feats160_predictions = zero_sum(feats160_predictions, test['bid_size'] + test['ask_size'])\n",
    "    clipped_predictions = np.clip(feats160_predictions, y_min, y_max)\n",
    "    sample_prediction['target'] = 0.5*sample_prediction['target']+ 0.5*clipped_predictions\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    env.predict(sample_prediction)\n",
    "    counter += 1\n",
    "    qps.append(time.time() - now_time)\n",
    "    if counter % 10 == 0:\n",
    "        print(counter, 'qps:', np.mean(qps))\n",
    "time_cost = 1.146 * np.mean(qps)\n",
    "print(f\"The code will take approximately {np.round(time_cost, 4)} hours to reason about\")"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "none",
   "dataSources": [
    {
     "databundleVersionId": 7056235,
     "sourceId": 57891,
     "sourceType": "competition"
    },
    {
     "datasetId": 4090391,
     "sourceId": 7161496,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 4085310,
     "sourceId": 7243094,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 4153078,
     "sourceId": 7215388,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 4143752,
     "sourceId": 7226619,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 4139863,
     "sourceId": 7234225,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 4030174,
     "sourceId": 7239122,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 4138844,
     "sourceId": 7239152,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 30626,
   "isGpuEnabled": false,
   "isInternetEnabled": false,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 750.82459,
   "end_time": "2023-12-20T04:02:06.245217",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2023-12-20T03:49:35.420627",
   "version": "2.4.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
